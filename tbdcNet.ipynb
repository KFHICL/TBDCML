{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tow-Based Discontinuous Composite (TBDC) property predictor\n",
        "This code is written for an MSc research project at Imperial College London"
      ],
      "metadata": {
        "id": "6WRTqatANXtY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount drive"
      ],
      "metadata": {
        "id": "9ZSQj-VW6z8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data to be imported from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set path for drive with datasets\n",
        "drive_path =\"/content/drive/MyDrive/Individual_project_ICL\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh9VEJVE6xgR",
        "outputId": "759d3116-1756-4fef-e341-9496bbceb8ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and installs"
      ],
      "metadata": {
        "id": "5uTIclYd7cQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install tensorflow\n",
        "!{sys.executable} -m pip install matplotlib\n",
        "!{sys.executable} -m pip install pandas"
      ],
      "metadata": {
        "id": "hiF8_uHZ6wkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "import datetime\n",
        "import shutil\n",
        "import json\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "T8TeyIOX7mI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import data\n"
      ],
      "metadata": {
        "id": "8EME7e-h8Zbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "range(8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt6Xv8kzLIyG",
        "outputId": "24da5b82-527a-4d4e-8bb5-73e7bc9d40ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of parallel jobs run on HPC specified for data loading as filenaming done based on this:\n",
        "numP = 8\n",
        "runName = 'TEST'\n",
        "\n",
        "# Create empty arrays for data to be loaded:\n",
        "theta_t = np.array()\n",
        "Q_g = np.array()\n",
        "overlap_lengths = np.array()\n",
        "overlap_thicknesses = np.array()\n",
        "sigma_l = np.array()\n",
        "failure_factors = np.array()\n",
        "theta_t2 = np.array()\n",
        "failure_factors2 = np.array() # Failure factor 2 is a repeat computation of the failure factor where the only difference is another random layup sequence defined by theta_t2\n",
        "\n",
        "for i in range(numP):\n",
        "  # Read data from json file in google drive\n",
        "  dataPath = os.path.join(drive_path,runName,str(i+1),'.json')\n",
        "\n",
        "  with open(dataPath) as json_file: # load into dict\n",
        "    dat = json.load(json_file)\n",
        "\n",
        "  # Append data to numpy arrays for each parallel run to get one variable with each\n",
        "  theta_t = np.append(theta_t,dat['theta_t'])\n",
        "  Q_g = np.append(Q_g,dat['Q_g'])\n",
        "  overlap_lengths = np.append(overlap_lengths,dat['overlap_lengths'])\n",
        "  overlap_thicknesses = np.append(overlap_thicknesses,dat['overlap_thicknesses'])\n",
        "  sigma_l = np.append(sigma_l,dat['sigma_l'])\n",
        "  failure_factors = np.append(failure_factors,dat['failure_factors'])\n",
        "  theta_t2 = np.append(theta_t2,dat['theta_t2'])\n",
        "  failure_factors2 = np.append(failure_factors2,dat['failure_factors2'])\n",
        "\n",
        "\n",
        "# params = list(dat.keys()) # get list of parameters in file\n",
        "# print(params)\n",
        "\n",
        "\n",
        "\n",
        "# # Read data from txt file in format \"parameter:value\"\\n e.g. N_t:[8, 8]\\n\n",
        "# with open(drive_path + '/datDumpTest.json') as f:\n",
        "#     dat = f.read()\n",
        "# dat = dat.splitlines() # split into string array by linebreaks\n",
        "\n",
        "# namesToLoad = ['theta_t', 'failure_factors'] # set variables to load\n",
        "# datDict = {} # create dictionary to store data, for easier debugging\n",
        "\n",
        "# for n in namesToLoad: # For each variable to be loaded\n",
        "#     paramStr = [match for match in dat if n+':' in match] # find all string array entries with the given parameter name (use \":\" to ensure only the actual variable is taken)\n",
        "#     varname = paramStr[0].split(':')[0] # Set variable name for dictionary\n",
        "#     datDict[varname] = paramStr[0].split(':')[-1] # assign key and value for parameter in dictionary\n",
        "# # np.array()\n",
        "# theta_t = datDict['theta_t'] # Angle of each ply in laminate\n",
        "# failure_factors = datDict['failure_factors'] #\n",
        "\n",
        "# failure_factors = np.array(list(failure_factors), dtype=float)\n",
        "# print(failure_factors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFZSfkqD8p5r",
        "outputId": "a04c04bc-4201-417b-f847-b4d50d723961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['theta_t', 'Q_g', 'overlap_lengths', 'overlap_thicknesses', 'sigma_l', 'failure_factors']\n"
          ]
        }
      ]
    }
  ]
}